# -*- coding: utf-8 -*-
"""Langchain GenAi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15EtPrRjs8mpCMR6l9lMlGMuxOAkRlWmr
"""

!pip install -U langchain

!pip install -U langchain-google-genai

from google.colab import userdata
key = userdata.get('ApiKey')

from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    api_key=key,
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2
)

'''messages = [
    (
        "system",
        "You are a helpful assistant that know about Bangladesh. Answer the user questions about bangladesh to the point.",
    ),
    ("human", "When Bangladesh's Victory Day?"),
]
ai_msg = llm.invoke(messages)
print(ai_msg.content)'''

!pip install streamlit

import streamlit as st

st.title("ðŸ‡§ðŸ‡© Bangladesh Q&A Chatbot ðŸ‡§ðŸ‡©")

st.write("Ask anything about Bangladesh. The answer will be short and to-the-point.")

user_input = st.text_input("Your Question:")

col1, col2 = st.columns(2)

if "response" in st.session_state:
    response_text = st.session_state["response"]
else:
    response_text = ""

# Submit button
with col1:
    if st.button("Submit"):
        if user_input.strip():
            messages = [
                (
                    "system",
                    "You are a helpful assistant that knows about Bangladesh. Answer to-the-point.",
                ),
                ("human", user_input),
            ]
            ai_msg = llm.invoke(messages)
            st.session_state["response"] = ai_msg.content
            st.experimental_rerun()

# Clear button
with col2:
    if st.button("Clear"):
        st.session_state["response"] = ""
        st.experimental_rerun()

# ---- Output Box ----
st.subheader("Answer:")
st.write(st.session_state.get("response", ""))

!streamlit run app.py --server.port 8501 --server.address 0.0.0.0